setwd("~/Desktop/Nimish/Columbia MPH/4. Spring 2023/Machine Learning in Epi/Assignments/Assignment 6/Week 6 R Demo")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rpart)
library(caret)
library(rpart.plot)
library(pROC)
chr<-read.csv("chr.csv")
#Stripping off ID Variable
chr<-chr[,2:68]
#Assigning informative variable names
var.names<-c("pre_death", "poorhealth", "poorphyshealth_days", "poormenthealth_days", "low_bwt", "ad_smoking", "ad_obesity", "foodenv_index", "phys_inactivity", "exer_access", "excess_drink", "alc_drivdeaths", "sti", "teen_birth", "uninsured", "primcareproviders", "dentists", "menthealthproviders", "prevhosp", "mammo_screen", "flu_vacc", "hsgrad", "somecollege", "unemployed", "child_poverty", "income_ineq", "sing_parent", "social_assoc", "violent_crime", "injury_deaths", "pm_air", "water_viol", "housing_prob", "driving_alone", "long_commute", "life_exp", "age_adj_premortality", "freq_physdistress", "freq_mentdistress", "diabetes", "hiv", "food_insecure", "ltd_access_healthyfood", "mvcrash_deaths", "insuff_sleep", "uninsured_adults", "uninsured_child", "other_pcp", "medhhinc", "freelunch_child", "res_seg_bw", "res_seg_nw", "firearm_fatalities", "homeownership", "hous_cost_burden", "population", "bw18", "gte65", "nonhisp_afam", "AmerInd_AlasNative", "Asian", "OPacIslander", "Hisp", "nonhisp_white", "nonprof_english", "female", "rural")
colnames(chr)<-var.names
#Stripping off premature mortality and premature death as they are different metrics of mortality that will improve prediction of
chr$age_adj_premortality<-NULL
chr$pre_death<-NULL
#Will identify any rows that do not have complete cases (i.e. have missing data); these data have no missing values
miss.rows<-chr[!complete.cases(chr),]
summary(chr)
chr$firearm.class<-as.factor(ifelse(chr$firearm_fatalities>median(chr$firearm_fatalities),1,0))
summary(chr$firearm.class)
set.seed(123)
#To address Question 1
training.data.q1<-chr$life_exp %>% createDataPartition(p=0.7, list=F)
train.data.q1<-chr[training.data.q1, ]
test.data.q1<-chr[-training.data.q1, ]
#Remove firearm.class variable as its only used for Question 2
train.data.q1$firearm.class<-NULL
test.data.q1$firearm.class<-NULL
#To address Question 2
training.data.q2<-chr$firearm.class%>% createDataPartition(p=0.7, list=F)
train.data.q2<-chr[training.data.q2, ]
test.data.q2<-chr[-training.data.q2, ]
#Remove firearm fatalities variable as it was used to create our new outcome variable
train.data.q2$firearm_fatalities<-NULL
test.data.q2$firearm_fatalities<-NULL
modelLookup("rpart")
set.seed(123)
#Using 10-fold cross-validation to train model
train.control<-trainControl(method="cv", number=10)
#Using rpart method to generate regression tree, using all variables in dataset to predict life expectancy
tree.lifexp.1<-train(life_exp~ . , data=train.data.q1, method="rpart",trControl=train.control)
tree.lifexp.1$bestTune
tree.lifexp.1$results
#Can use rpart.plot function to visualize tree
rpart.plot(tree.lifexp.1$finalModel)
library(tidyverse)
library(rpart)
library(caret)
library(rpart.plot)
library(pROC)
set.seed(123)
#Using 10-fold cross-validation to train model
train.control<-trainControl(method="cv", number=10)
#Using rpart method to generate regression tree, using all variables in dataset to predict life expectancy
tree.lifexp.1<-train(life_exp~ . , data=train.data.q1, method="rpart",trControl=train.control)
tree.lifexp.1$bestTune
tree.lifexp.1$results
#Can use rpart.plot function to visualize tree
rpart.plot(tree.lifexp.1$finalModel)
#First create predictions
pred.intest.temp<-predict(tree.lifexp.1, newdata=test.data.q1)
#Then use postResample to obtain evaluation metrics
postResample(pred.intest.temp, test.data.q1$life_exp)
#Specify tuneGrid so caret explores wider variety of cp-values
set.seed(123)
#Create different values of cp to try
cp.grid<-expand.grid(cp=seq(0.001,0.1, by=0.001))
tree.lifexp.2<-train(life_exp ~ ., data=train.data.q1, method="rpart", trControl=train.control, tuneGrid=cp.grid)
#Plot new "best" tree
rpart.plot(tree.lifexp.2$finalModel)
tree.lifexp.2$bestTune
pred.intest.2<-predict(tree.lifexp.2, newdata=test.data.q1)
#Then use postResample to obtain evaluation metrics
postResample(pred.intest.2, test.data.q1$life_exp)
#Example variable importance in final model
varImp(tree.lifexp.2)
#Sample code using rpart without caret, unpruned tree
tree.lifexp.3<-rpart(life_exp ~ ., data=train.data.q1, method="anova")
plot(tree.lifexp.3, uniform=TRUE)
text(tree.lifexp.3, use.n=TRUE, all=TRUE, cex=0.8)
printcp(tree.lifexp.3)
plotcp(tree.lifexp.3)
print(tree.lifexp.3)
rpart.plot(tree.lifexp.3)
pred.intest.3 <- predict(tree.lifexp.3, test.data.q1$life_exp)
pred.intest.3 <- predict(tree.lifexp.3, newdata = test.data.q1)
postResample(pred.intest.3, test.data.q1$life_exp)
varImp(tree.lifexp.3)
set.seed(123)
#Creating 10-fold cross-validation and using down-sampling because of imbalance in data
train.control.class<-trainControl(method="cv", number=10, sampling="down")
#Create sequence of cp parameters to try
grid.2<-expand.grid(cp=seq(0.001, 0.3, by=0.01))
#Train model
tree.firearm<-train(firearm.class~., data=train.data.q2, method="rpart",trControl=train.control.class, tuneGrid=grid.2)
tree.firearm$bestTune
tree.firearm
rpart.plot(tree.firearm$finalModel)
#Note you can obtain variable importance on the final model within training data
varImp(tree.firearm)
#Note you can get accuracy metric and confusion matrix from training.
confusionMatrix(tree.firearm)
#Create predictions in test set
pred.firearm<-predict(tree.firearm, test.data.q2)
#Create predictions as probabilities on test set
pred.firearm.prob<-predict(tree.firearm, test.data.q2, type="prob")
eval.results<-confusionMatrix(pred.firearm, test.data.q2$firearm.class, positive = "1")
print(eval.results)
#Another potential evaluation: Area under the Receiver Operating Curve (AUROC)
analysis <- roc(response=test.data.q2$firearm.class, predictor=pred.firearm.prob[,2])
plot(1-analysis$specificities,analysis$sensitivities,type="l",
ylab="Sensitivity",xlab="1-Specificity",col="black",lwd=2,
main = "ROC Curve for Greater Firearm Fatalities")
abline(a=0,b=1)
setwd("~/Desktop/Nimish/Columbia MPH/4. Spring 2023/Master's Thesis I")
prep2 <- read.csv("PREP2.csv") %>%
clean_names()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(janitor)
library(gapminder)
library(kableExtra)
library(gtsummary)
library(ROCR)
prep2 <- read.csv("PREP2.csv") %>%
clean_names()
prep2 <- read.csv("PREP2.csv") %>%
clean_names()
ggplot(data = prep2, aes(y = hfd, x = rfs_aspen))+
geom_boxplot()
ggplot(data = prep2, aes(y = hfd, group = rfs_aspen))+
geom_boxplot()
prep2 %>%
select(hfd>0) %>%
ggplot(aes(y = hfd, group = rfs_aspen))+
geom_boxplot()
prep2 %>%
select(hfd>0) %>%
ggplot(aes(y = hfd, group = rfs_aspen))+
geom_boxplot()
prep2 %>%
select(hfd>0) %>%
ggplot(data = prep2, aes(y = hfd, group = rfs_aspen))+
geom_boxplot()
prep2 %>%
select(hfd>0) %>%
ggplot(data = prep2, aes(y = hfd, group = rfs_aspen))+
geom_boxplot()
prep2
prep2 %>%
select(hfd>0)
prep2 %>%
select(prep2$hfd>0)
prep2 <- read.csv("PREP2.csv") %>%
clean_names()
ggplot(data = prep2, aes(y = hfd, group = rfs_aspen))+
geom_boxplot(aes(color = rfs_aspen))
ggplot(data = prep2, aes(y = hfd, group = rfs_aspen))+
geom_boxplot(aes(fill = rfs_aspen))
ggplot(data = prep2, aes(y = hfd, group = rfs_aspen))+
geom_boxplot(aes(fill = rfs_aspen), color = "black")
ggplot(data = prep2, aes(y = hfd, group = phosrel))+
geom_boxplot(aes(fill = rfs_aspen), color = "black")
ggplot(data = prep2, aes(y = hfd, group = phosrel))+
geom_boxplot(aes(fill = phosrel), color = "black")
ggplot(data = prep2, aes(y = hfd, group = phosrel))+
geom_boxplot(aes(fill = phosrel), color = "white")
setwd("~/Desktop/Nimish/Columbia MPH/4. Spring 2023/Machine Learning in Epi/Assignments/Assignment 5")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(yardstick)
library(stats)
library(factoextra)
library(cluster)
library(caret)
set.seed(123)
#Loading in Data
a5.data <- read.csv("~/Desktop/Nimish/Columbia MPH/4. Spring 2023/Machine Learning in Epi/Assignments/Assignment 5/alcohol_use.csv") %>%
clean_names()
#Convert all categorical variables to factors
a5.data <- a5.data %>%
mutate(alc_consumption = as.factor(alc_consumption))
#Strip ID
a5.data$x <- NULL
#Remove Missing Variables
a5.data <- na.omit(a5.data)
#Check Data Structure
str(a5.data)
#Finding correlated predictors
a5.data.numeric <- a5.data %>% dplyr::select(where(is.numeric))
correlations<-cor(a5.data.numeric, use="complete.obs")
high.correlations<-findCorrelation(correlations, cutoff=0.4) #None Found
a5.data.lowcor<-a5.data[,-high.correlations]
#Centering and Scaling
set.up.preprocess<-preProcess(a5.data.lowcor, method=c("center", "scale"))
#Output pre-processed values
transformed.vals<-predict(set.up.preprocess, a5.data.lowcor)
#Output pre-processed values
transformed.vals<-predict(set.up.preprocess, a5.data.lowcor)
### Step 2: Data Partitioning
set.seed(123)
train.index<-createDataPartition(transformed.vals$alc_consumption, p=0.7, list=FALSE)
a5.data.train<-transformed.vals[train.index,]
a5.data.test<-transformed.vals[-train.index,]
#Construct k-folds in your data
train.folds<-createFolds(transformed.vals$alc_consumption, k=10, list=FALSE)
set.seed(123)
en.model<- train(alc_consumption ~., data = a5.data.train,
method = "glmnet",
trControl = trainControl("cv", number = 10),
preProc=c("center", "scale"),
tuneLength=10
)
#Print all of the options examined
en.model$results$accuracy
#Print all of the options examined
en.model$results$Accuracy
#Print the values of alpha and lambda that gave best prediction
en.model$bestTune
#Print all of the options examined
en.model$results$Accuracy[36]
lasso.model$bestTune
set.seed(123)
#Create grid to search lambda
lambda<-10^seq(-3,3, length=100) #Creating lambda grid
#Training a Lasso Model
lasso.model <- train(alc_consumption ~., data=a5.data.train,
method="glmnet",
trControl=trainControl("cv", number=10),
preProc=c("center", "scale"),
tuneGrid=expand.grid(alpha=1, lambda=lambda)
)
lasso.model$bestTune
lasso.model$results$Accuracy[40]
