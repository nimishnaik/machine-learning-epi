labs(title = "Proportion of patients with Positive Diagnosis for RFS by RFS Definition",
x = "Definition",
y = "Percent with RFS") +
theme(panel.background = element_rect(fill = "white")) +
theme(axis.title = element_text(size = 16))
ggplot(data = rfs_prop, aes(x = reorder(definiton, -rfs_positive), y = rfs_positive)) +
geom_bar(aes(fill = definiton), stat = "identity", colour = "black", width = 0.7) +
geom_text(aes(label = round(rfs_positive,2)), nudge_y = 2, color = "black") +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(face = "bold"),
plot.title = element_text(face = "bold", size = 16)) +
labs(title = "Proportion of patients with Positive Diagnosis for RFS by RFS Definition",
x = "Definition",
y = "Percent with RFS") +
theme(panel.background = element_rect(fill = "white")) +
theme(axis.title = element_text(size = 16))
deathprops <- read_excel("Refeeding Thesis Data.xlsx", sheet = 2) %>%
clean_names()
deathprops <- deathprops %>%
mutate(deathprop = (deaths/395)*100,
rfsprop = (row_total/2123)*100,
rfs = factor(rfs)) %>%
arrange(rfs, -deathprop)
deathprops <- read_excel("Refeeding Thesis Data.xlsx", sheet = 2) %>%
clean_names()
deathprops <- deathprops %>%
mutate(deathprop = (deaths/395)*100,
rfsprop = (row_total/2123)*100,
rfs = factor(rfs)) %>%
arrange(rfs, -deathprop)
deathprops <- read_excel("Refeeding Thesis Data.xlsx", sheet = 2) %>%
clean_names()
deathprops <- deathprops %>%
mutate(deathprop = (deaths/395)*100,
rfsprop = (row_total/2123)*100,
rfs = factor(rfs))
deathprops <- deathprops %>%
mutate(deathprop = (deaths/406)*100,
rfs = factor(rfs)) %>%
arrange(rfs, -deathprop)
kable(deathprops)
ggplot(data = deathprops, aes(fill = rfs,
x = fct_relevel(definition, "K Relative Decrease", "Phos Nadir", "K, Mg, Phos Nadir", "Phos Relative Decrease", "K, Mg, Phos Relative Decrease", "Phos Absolute Decrease", "K, Mg, Phos Absolute Decrease", "ASPEN"), y = deathprop)) +
geom_bar(stat = "identity", position = position_dodge2(), colour = "black") +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
plot.title = element_text(face = "bold", size = 20)) +
scale_fill_discrete(name = "RFS Diagnosis", labels = c("Present", "Absent")) +
labs(title = "Proportion of Deaths with and without RFS Diagnosis by RFS Definition",
x = "Definition",
y = "Percent Deaths",
align = "c")
View(deathprops)
deathprops <- deathprops %>%
mutate(deathprop = (deaths/406)*100,
rfs = factor(rfs)) %>%
arrange(-rfs, -deathprop)
kable(deathprops)
ggplot(data = deathprops, aes(fill = rfs,
x = fct_relevel(definition, "K Relative Decrease", "Phos Nadir", "K, Mg, Phos Nadir", "Phos Relative Decrease", "K, Mg, Phos Relative Decrease", "Phos Absolute Decrease", "K, Mg, Phos Absolute Decrease", "ASPEN"), y = deathprop)) +
geom_bar(stat = "identity", position = position_dodge2(), colour = "black") +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
plot.title = element_text(face = "bold", size = 20)) +
scale_fill_discrete(name = "RFS Diagnosis", labels = c("Present", "Absent")) +
labs(title = "Proportion of Deaths with and without RFS Diagnosis by RFS Definition",
x = "Definition",
y = "Percent Deaths",
align = "c")
ggplot(data = deathprops, aes(fill = rfs,
x = fct_relevel(definition, "K Relative Decrease", "Phos Nadir", "K, Mg, Phos Nadir", "Phos Relative Decrease", "K, Mg, Phos Relative Decrease", "Phos Absolute Decrease", "K, Mg, Phos Absolute Decrease", "ASPEN"), y = deathprop)) +
geom_bar(stat = "identity", position = position_dodge2(), colour = "black") +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
plot.title = element_text(face = "bold", size = 20)) +
scale_fill_discrete(name = "RFS Diagnosis", labels = c("Present", "Absent")) +
labs(title = "Proportion of Deaths with and without RFS Diagnosis by RFS Definition",
x = "Definition",
y = "Percent Deaths",
align = "c")
View(deathprops)
deathprops <- deathprops %>%
mutate(deathprop = (deaths/406)*100,
rfs = factor(rfs)) %>%
arrange(-rfs, -deathprop)
deathprops <- deathprops %>%
mutate(deathprop = (deaths/406)*100,
rfs = factor(rfs)) %>%
arrange(rfs, -deathprop)
ggplot(data = deathprops, aes(fill = rfs,
x = fct_relevel(definition, "K Relative Decrease", "Phos Nadir", "K, Mg, Phos Nadir", "Phos Relative Decrease", "K, Mg, Phos Relative Decrease", "Phos Absolute Decrease", "K, Mg, Phos Absolute Decrease", "ASPEN"), y = deathprop)) +
geom_bar(stat = "identity", position = position_dodge2(), colour = "black") +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
plot.title = element_text(face = "bold", size = 20)) +
scale_fill_discrete(name = "RFS Diagnosis", labels = c("Absent", "Present")) +
labs(title = "Proportion of Deaths with and without RFS Diagnosis by RFS Definition",
x = "Definition",
y = "Percent Deaths",
align = "c")
View(deathprops)
ggplot(data = deathprops, aes(fill = rfs,
x = fct_relevel(definition, "ASPEN", "K, Mg, Phos Absolute Decrease","Phos Absolute Decrease", "K, Mg, Phos Relative Decrease","Phos Relative Decrease", "K, Mg, Phos Nadir", "Phos Nadir", "K Relative Decrease"), y = deathprop)) +
geom_bar(stat = "identity", position = position_dodge2(), colour = "black") +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
plot.title = element_text(face = "bold", size = 20)) +
scale_fill_discrete(name = "RFS Diagnosis", labels = c("Absent", "Present")) +
labs(title = "Proportion of Deaths with and without RFS Diagnosis by RFS Definition",
x = "Definition",
y = "Percent Deaths",
align = "c")
ggplot(data = deathprops, aes(fill = rfs,
x = fct_relevel(definition, "ASPEN", "K, Mg, Phos Absolute Decrease","Phos Absolute Decrease", "K, Mg, Phos Relative Decrease","Phos Relative Decrease", "K, Mg, Phos Nadir", "Phos Nadir", "K Relative Decrease"), y = deathprop)) +
geom_bar(stat = "identity", position = position_dodge2(), colour = "black") +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
plot.title = element_text(face = "bold", size = 20)) +
scale_fill_discrete(name = "RFS Diagnosis") +
labs(title = "Proportion of Deaths with and without RFS Diagnosis by RFS Definition",
x = "Definition",
y = "Percent Deaths",
align = "c")
ggplot(data = deathprops, aes(fill = rfs,
x = fct_relevel(definition, "ASPEN", "K, Mg, Phos Absolute Decrease","Phos Absolute Decrease", "K, Mg, Phos Relative Decrease","Phos Relative Decrease", "K, Mg, Phos Nadir", "Phos Nadir", "K Relative Decrease"), y = deathprop)) +
geom_bar(stat = "identity", position = position_dodge2(), colour = "black") +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
plot.title = element_text(face = "bold", size = 20)) +
scale_fill_discrete(name = "RFS Diagnosis", labels = c("Absent", "Present")) +
labs(title = "Proportion of Deaths with and without RFS Diagnosis by RFS Definition",
x = "Definition",
y = "Percent Deaths",
align = "c")
gc()
install.packages(c("broom", "class", "codetools", "colorspace", "dplyr", "e1071", "fansi", "forcats", "fs", "gargle", "ggplot2", "ggpubr", "janitor", "knitr", "lubridate", "markdown", "MASS", "nlme", "Rcpp", "RcppArmadillo", "readr", "readxl", "rmarkdown", "sass", "sp", "spatial", "survival", "terra", "tidyr", "tinytex", "utf8", "vctrs", "vroom", "xfun", "yaml"))
setwd("~/Desktop/Nimish/Columbia MPH/4. Spring 2023/Master's Thesis I")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(janitor)
library(gapminder)
library(kableExtra)
deathprops <- read_excel("Refeeding Thesis Data.xlsx", sheet = 2) %>%
clean_names()
deathprops <- deathprops %>%
mutate(deathprop = (deaths/total_deaths)*100,
rfs = factor(rfs)) %>%
arrange(rfs, -deathprop)
View(deathprops)
ggplot(data = deathprops, aes(fill = rfs,
x = fct_relevel(definition, "ASPEN", "K, Mg, Phos Absolute Decrease","Phos Absolute Decrease", "K, Mg, Phos Relative Decrease","Phos Relative Decrease", "K, Mg, Phos Nadir", "Phos Nadir", "K Relative Decrease"), y = deathprop)) +
geom_bar(stat = "identity", position = position_dodge2(), colour = "black") +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
plot.title = element_text(face = "bold", size = 20)) +
scale_fill_discrete(name = "RFS Diagnosis", labels = c("Absent", "Present")) +
labs(title = "Proportion of Deaths with and without RFS Diagnosis by RFS Definition",
x = "Definition",
y = "Percent Deaths",
align = "c")
ggplot(data = deathprops, aes(fill = rfs,
x = fct_relevel(definition, "K Relative Decrease", "Phos Nadir", "K, Mg, Phos Nadir", "Phos Relative Decrease", "K, Mg, Phos Relative Decrease", "Phos Absolute Decrease", "K, Mg, Phos Absolute Decrease", "ASPEN"), y = deathprop)) +
geom_bar(stat = "identity", position = position_dodge2(), colour = "black") +
theme_bw() +
theme(axis.title = element_text(face = "bold", size = 16),
plot.title = element_text(face = "bold", size = 20)) +
scale_fill_discrete(name = "RFS Diagnosis", labels = c("Absent", "Present")) +
labs(title = "Proportion of Deaths with and without RFS Diagnosis by RFS Definition",
x = "Definition",
y = "Percent Deaths",
align = "c")
library(gtsummary)
install.packages("gtsummary")
library(gtsummary)
tbl_summary(prep)
prep <- read.csv("thesis_prep_data.csv") %>%
clean_names()
tbl_summary(prep)
tbl_summary(deathprops)
tbl_summary(deathprops, by = rfs)
tbl_summary(deathprops, by = definition)
roc_curve <- read_excel("Refeeding Thesis Data.xlsx", sheet = 6) %>%
clean_names()
ggplot(data = roc_curve, aes(x = x1_specificity, y = sensitivity)) +
geom_point(color = "red") +
geom_smooth(se = FALSE, method = "loess", color = "darkred") +
geom_abline(slope = 1, alpha = 0.4)
install.packages("ROCR")
library(ROCR)
# Generate example data
set.seed(123)
probs <- runif(100)
labels <- rbinom(100, 1, 0.5)
# Compute the ROC curve
pred <- prediction(probs, labels)
perf <- performance(pred, "tpr", "fpr")
# Plot the ROC curve
plot(perf)
setwd("~/Desktop/Nimish/Columbia MPH/4. Spring 2023/Machine Learning in Epi/Week 5 R Demo")
set.seed(100)
chr<-read.csv("chr.csv")
#Strip off ID Variable
chr<-chr[,2:68]
#Add informative feature names
var.names<-c("pre_death", "poorhealth", "poorphyshealth_days", "poormenthealth_days", "low_bwt", "ad_smoking", "ad_obesity", "foodenv_index", "phys_inactivity", "exer_access", "excess_drink", "alc_drivdeaths", "sti", "teen_birth", "uninsured", "primcareproviders", "dentists", "menthealthproviders", "prevhosp", "mammo_screen", "flu_vacc", "hsgrad", "somecollege", "unemployed", "child_poverty", "income_ineq", "sing_parent", "social_assoc", "violent_crime", "injury_deaths", "pm_air", "water_viol", "housing_prob", "driving_alone", "long_commute", "life_exp", "age_adj_premortality", "freq_physdistress", "freq_mentdistress", "diabetes", "hiv", "food_insecure", "ltd_access_healthyfood", "mvcrash_deaths", "insuff_sleep", "uninsured_adults", "uninsured_child", "other_pcp", "medhhinc", "freelunch_child", "res_seg_bw", "res_seg_nw", "firearm_fatalities", "homeownership", "hous_cost_burden", "population", "bw18", "gte65", "nonhisp_afam", "AmerInd_AlasNative", "Asian", "OPacIslander", "Hisp", "nonhisp_white", "nonprof_english", "female", "rural")
colnames(chr)<-var.names
train.indices<-createDataPartition(y=chr$life_exp,p=0.7,list=FALSE)
library(tidyverse)
library(caret)
library(glmnet)
library(klaR)
train.indices<-createDataPartition(y=chr$life_exp,p=0.7,list=FALSE)
train.data<-chr[train.indices, ]
test.data<-chr[-train.indices, ]
library(klaR)
set.seed(123)
en.model<- train(
life_exp ~., data = train.data, method = "glmnet",
trControl = trainControl("cv", number = 10), preProc=c("center", "scale"),
tuneLength=10
)
#Print the values of alpha and lambda that gave best prediction
en.model$bestTune
#Print all of the options examined
en.model$results
# Model coefficients
coef(en.model$finalModel, en.model$bestTune$lambda)
en.pred <- en.model %>% predict(test.data)
# Model prediction performance
postResample(en.pred,test.data$life_exp)
data.frame(
RMSE = RMSE(en.pred, test.data$life_exp),
Rsquare = R2(en.pred, test.data$life_exp)
)
library(tidyverse)
library(caret)
library(glmnet)
library(klaR)
set.seed(123)
chr<-read.csv("chr.csv")
#Strip off ID Variable
chr<-chr[,2:68]
#Add informative feature names
var.names<-c("pre_death", "poorhealth", "poorphyshealth_days", "poormenthealth_days", "low_bwt", "ad_smoking", "ad_obesity", "foodenv_index", "phys_inactivity", "exer_access", "excess_drink", "alc_drivdeaths", "sti", "teen_birth", "uninsured", "primcareproviders", "dentists", "menthealthproviders", "prevhosp", "mammo_screen", "flu_vacc", "hsgrad", "somecollege", "unemployed", "child_poverty", "income_ineq", "sing_parent", "social_assoc", "violent_crime", "injury_deaths", "pm_air", "water_viol", "housing_prob", "driving_alone", "long_commute", "life_exp", "age_adj_premortality", "freq_physdistress", "freq_mentdistress", "diabetes", "hiv", "food_insecure", "ltd_access_healthyfood", "mvcrash_deaths", "insuff_sleep", "uninsured_adults", "uninsured_child", "other_pcp", "medhhinc", "freelunch_child", "res_seg_bw", "res_seg_nw", "firearm_fatalities", "homeownership", "hous_cost_burden", "population", "bw18", "gte65", "nonhisp_afam", "AmerInd_AlasNative", "Asian", "OPacIslander", "Hisp", "nonhisp_white", "nonprof_english", "female", "rural")
colnames(chr)<-var.names
train.indices<-createDataPartition(y=chr$life_exp,p=0.7,list=FALSE)
train.data<-chr[train.indices, ]
test.data<-chr[-train.indices, ]
set.seed(123)
en.model<- train(
life_exp ~., data = train.data, method = "glmnet",
trControl = trainControl("cv", number = 10), preProc=c("center", "scale"),
tuneLength=10
)
#Print the values of alpha and lambda that gave best prediction
en.model$bestTune
# Model coefficients
coef(en.model$finalModel, en.model$bestTune$lambda)
#Print all of the options examined
en.model$results
# Model coefficients
coef(en.model$finalModel, en.model$bestTune$lambda)
en.pred <- en.model %>% predict(test.data)
postResample(en.pred,test.data$life_exp) #First way to do it
data.frame(
RMSE = RMSE(en.pred, test.data$life_exp),
Rsquare = R2(en.pred, test.data$life_exp)
)
#Create grid to search lambda
lambda<-10^seq(-3,3, length=100)
set.seed(123)
#Create grid to search lambda
lambda<-10^seq(-3,3, length=100)
#Note replacing tuneLength with tuneGrid
model.4 <- train(life_exp ~., data=train.data,
method="glmnet",
trControl=trainControl("cv", number=10),
preProc=c("center", "scale"),
tuneGrid=expand.grid(alpha=0, lambda=lambda) #This is how we add our own lambda grid
)
model.4$bestTune
model.4$results
results <- model.4$results %>%
arrange(RMSE)
results
results <- model.4$results %>%
arrange(RMSE)
results
model.4$bestTune
#Note replacing tuneLength with tuneGrid
model.ridge <- train(life_exp ~., data=train.data,
method="glmnet",
trControl=trainControl("cv", number=10),
preProc=c("center", "scale"),
tuneGrid=expand.grid(alpha=0, lambda=lambda) #This is how we add our own lambda grid, alpha 0
)
model.lasso <- train(life_exp ~., data=train.data,
method="glmnet",
trControl=trainControl("cv", number=10),
preProc=c("center", "scale"),
tuneGrid=expand.grid(alpha=1, lambda=lambda) #This is how we add our own lambda grid, alpha 1
)
model.ridge$bestTune
model.lasso$bestTune
results <- model.4$results
model.ridge$results
set.seed(123)
hcvdat0 <- read.csv("hcvdat0.csv")
#Look at features
str(hcvdat0)
#drop ID and sex variables because K-means is based on distance so we only need numeric variables
hcvdat0$X<-NULL
hcvdat0$Sex<-NULL
#Make outcome category a factor var
hcvdat0$Category<-as.factor(hcvdat0$Category)
#Collapse factor levels of outcome variable
hcvdat0$outcome.class<-fct_collapse(hcvdat0$Category, NED=c("0=Blood Donor","0s=suspect Blood Donor"), LiverDisease=c("1=Hepatitis", "2=Fibrosis", "3=Cirrhosis"))
set.seed(123)
hcvdat0 <- read.csv("hcvdat0.csv")
#Look at features
str(hcvdat0)
#drop ID and sex variables because K-means is based on distance so we only need numeric variables
hcvdat0$X<-NULL
hcvdat0$Sex<-NULL
#Make outcome category a factor var
hcvdat0$Category<-as.factor(hcvdat0$Category)
#Collapse factor levels of outcome variable
hcvdat0$outcome.class<-fct_collapse(hcvdat0$Category, NED=c("0=Blood Donor","0s=suspect Blood Donor"), LiverDisease=c("1=Hepatitis", "2=Fibrosis", "3=Cirrhosis"))
#Drop category
hcvdat0$Category<-NULL
#Check distributions, missing data etc.
summary(hcvdat0)
#Omit those with missing data
hcvdata<-na.omit(hcvdat0)
#Split data 70/30
train.indices<-hcvdata$outcome.class %>% createDataPartition(p=0.7, list=F)
train.data<-hcvdata[train.indices, ]
test.data<-hcvdata[-train.indices, ]
#Set control options..using 10-fold cross-validation and using under-sampling due to unbalanced data
trnctrl<-trainControl(method="cv", number=10, sampling="down")
knn.model.1<-train(outcome.class~.  , data=train.data,
method="knn",
trControl=trnctrl,
preProcess=c("center", "scale"),
tuneLength=10)
#Identify optimal number of k
knn.model.1$bestTune
#See full set of results
knn.model.1$results
plot(knn.model.1$results$k, knn.model.1$results$Accuracy, type="l")
#REPEAT using over-sampling due to unbalanced data
set.seed(123)
trnctrl<-trainControl(method="cv", number=10, sampling="up")
knn.model.2<-train(outcome.class~.  , data=train.data,
method="knn",
trControl=trnctrl,
preProcess=c("center", "scale"),
tuneLength=10)
knn.model.2$bestTune
plot(knn.model.2$results$k, knn.model.2$results$Accuracy, type="l")
k.vec<-seq(1,5,1)
knn.model.3<-train(outcome.class~.  , data=train.data,
method="knn",
trControl=trnctrl,
preProcess=c("center", "scale"),
tuneGrid=expand.grid(k=k.vec))
#Identify optimal number of k
knn.model.3$bestTune
#See full set of results
knn.model.3$results
plot(knn.model.3$results$k, knn.model.3$results$Accuracy, type="l")
model.results.3<-predict(knn.model.3, newdata=test.data)
confusionMatrix(model.results.3, test.data$outcome.class, positive="LiverDisease")
set.seed(123)
nb_test <- read.csv("nb_test.csv")
#Remove missings
nb.test<-na.omit(nb_test)
nb.test[sapply(nb.test,is.numeric)]<-lapply(nb.test[sapply(nb.test,is.numeric)],as.factor)
train.indices<-createDataPartition(y=nb.test$COD,p=0.7,list=FALSE)
train.data.int<-nb.test[train.indices,2:7]
test.data.int<-nb.test[-train.indices,2:7]
train.data<-train.data.int[,1:5]
train.cod<-train.data.int[,6]
test.data<-test.data.int[,1:5]
test.cod<-as.factor(test.data.int[,6])
control.settings<-trainControl(method='cv', number=5)
nb.model<-train(train.data, train.cod, method='nb', trControl=control.settings)
nb.model$results
nb.pred<-predict(nb.model, test.data)
confusionMatrix(nb.pred,test.cod)
library(tidyverse)
library(janitor)
library(ggbiplot)
library(stats)
library(factoextra)
library(cluster)
library(caret)
setwd("~/Desktop/Nimish/Columbia MPH/4. Spring 2023/Machine Learning in Epi/Assignments/Assignment 4")
#Loading in Data
a4.data<-read.csv("~/Desktop/Nimish/Columbia MPH/4. Spring 2023/Machine Learning in Epi/Assignments/Assignment 4/class4_p1.csv")
library(tidyverse)
library(janitor)
library(ggbiplot)
library(stats)
library(factoextra)
library(cluster)
library(caret)
set.seed(123)
#Loading in Data
a4.data<-read.csv("~/Desktop/Nimish/Columbia MPH/4. Spring 2023/Machine Learning in Epi/Assignments/Assignment 4/class4_p1.csv")
#Rename Dataset based on the code book
a4.data <- a4.data %>%
dplyr::rename(hypertension = chronic1,
diabetes = chronic3,
asthma = chronic4,
cig_use = tobacco1,
alc_drink = alcohol1,
pa_min = gpaq8totmin,
walk_days = gpaq11days,
pa_yn = habits5,
diet = habits7,
gender = dem3,
hispanic = dem4,
us_citizen = dem8)
#Convert all categorical variables to factors
a4.data <- a4.data %>%
mutate(hypertension = as.factor(hypertension),
diabetes = as.factor(diabetes),
asthma = as.factor(asthma),
cig_use = as.factor(cig_use),
alc_drink = as.factor(alc_drink),
pa_yn = as.factor(pa_yn),
agegroup = as.factor(agegroup),
diet = as.factor(diet),
gender = as.factor(gender),
hispanic = as.factor(hispanic),
us_citizen = as.factor(us_citizen),
povertygroup = as.factor(povertygroup))
#Strip ID
a4.data$X <- NULL
#Remove Missing Variables
a4.data <- na.omit(a4.data)
#Check Data Structure
str(a4.data)
#Finding correlated predictors
a4.data.numeric <- a4.data %>% dplyr::select(where(is.numeric))
correlations<-cor(a4.data.numeric, use="complete.obs")
high.correlations<-findCorrelation(correlations, cutoff=0.4) #None Found
#Centering and Scaling
set.up.preprocess<-preProcess(a4.data, method=c("center", "scale"))
#Output pre-processed values
transformed.vals<-predict(set.up.preprocess, a4.data)
set.seed(123)
train.index<-createDataPartition(transformed.vals$healthydays, p=0.7, list=FALSE)
a4.data.train<-transformed.vals[train.index,]
a4.data.test<-transformed.vals[-train.index,]
#Construct k-folds in your data
train.folds<-createFolds(transformed.vals$healthydays, k=10, list=FALSE)
set.seed(123)
#Model 1: Comorbidities and Some Modifiable Factors
model1 <- lm(healthydays ~ hypertension + diabetes + bmi + alc_drink + cig_use, data = a4.data.train)
#Model 2: Modifiable Factors and Demographic
model2 <- lm(healthydays ~ cig_use + alc_drink + diet + agegroup + gender + povertygroup + bmi,
data = a4.data.train)
set.seed(123)
#Applying the Predictions
prediction1 <- predict(model1, a4.data.test)
prediction2 <- predict(model2, a4.data.test)
set.seed(123)
#Checking the Mean Square Errors
rmse1 <- RMSE(prediction1, a4.data.test$healthydays)
rmse2 <- RMSE(prediction2, a4.data.test$healthydays)
set.seed(123)
#Load in the Data
arrest.data <- USArrests
#Deleting any missing data
arrest.data<-na.omit(arrest.data)
#Check means and SDs to determine if scaling is necessary
colMeans(arrest.data, na.rm=TRUE)
apply(arrest.data, 2, sd, na.rm=TRUE)
#Is scaling necessary? Yes, scaling is necessary.
#Centering and Scaling
set.up.preprocess2 <- preProcess(arrest.data, method=c("center", "scale"))
#Output pre-processed values
arrest.transformed <- predict(set.up.preprocess2, arrest.data)
#Check means and SDs to check if scaling worked
colMeans(arrest.transformed, na.rm=TRUE)
apply(arrest.transformed, 2, sd, na.rm=TRUE)
set.seed(123)
# Create Dissimilarity matrix
diss.matrix <- dist(arrest.transformed, method = "euclidean")
# Hierarchical clustering using Complete Linkage
clusters.h<- hclust(diss.matrix, method = "complete")
# Plot the obtained dendrogram
plot(clusters.h, cex = 0.6, hang = -1)
gap_stat2 <- clusGap(arrest.transformed, FUN = hcut, K.max = 10, B = 50)
gap_stat2
fviz_gap_stat(gap_stat2)
set.seed(123)
#Create 3 clusters
clusters.hcut<-hcut(arrest.transformed, k=3, hc_func="hclust", hc_method="complete", hc_metric="euclidian")
#Output size, dendrogram, and  plot of the 3 clusters
clusters.hcut$size
fviz_dend(clusters.hcut, rect=TRUE)
fviz_cluster(clusters.hcut)
input.feature.vals<-cbind(arrest.transformed,cluster=clusters.hcut$cluster)
cluster_info <- input.feature.vals %>%
group_by(cluster) %>%
summarise_all(mean)
#Cluster Table
knitr::kable(cluster_info)
